{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ea433f2",
   "metadata": {},
   "source": [
    "# Homework 3: Regression and Correlation\n",
    "\n",
    "**File name:**  \n",
    "> Please save and submit your work as  \n",
    "> **`Homework3_py_Firstname_Lastname.ipynb`**\\\n",
    "> Please submit only the `.ipynb` file, unless otherwise stated.\\\n",
    "> The examiner will place your file into the appropriate environment where all required data files are available in the same directory.\n",
    "---\n",
    "\n",
    "**Before you start**\n",
    "- Record **how much time** the homework takes you in total.  \n",
    "  At the **end of the notebook** there is a cell where you can write the number of hours (for course development feedback).  \n",
    "\n",
    "---\n",
    "\n",
    "**General instructions**\n",
    "1. **Work individually.**  \n",
    "   You may **discuss ideas** with classmates, but **do not copy–paste** each other’s code.  \n",
    "   Each notebook must represent your own independent work.\n",
    "\n",
    "2. **Use of external materials and AI tools.**  \n",
    "   You may use course materials, documentation, examples, or quick help from sources such as Stack Overflow or ChatGPT.  \n",
    "   However, if you **heavily rely** on external material or AI-generated code (for example, by copying significant parts),  \n",
    "   please **cite the source**. There is **no need to cite** small pieces of help used only to understand or debug your code.\n",
    "\n",
    "3. **Do not delete notebook cells.**  \n",
    "   Please do **not remove any pre-existing cells**. Only add your own solutions in the designated places.  \n",
    "   If you accidentally delete a cell, use **`Edit → Undo Delete Cells`** to restore it.  \n",
    "   You may add extra cells if needed, but make sure every solution is placed **under the correct question or sub-question**.  \n",
    "   This structure helps us to evaluate your work efficiently and accurately.\n",
    "---\n",
    "\n",
    "**Installing and loading packages**\\\n",
    "The notebook begins with a code cell that imports the main packages required for this assignment.\\\n",
    "If any import fails on your machine, install the missing package using: `!pip install package_name` and then rerun the cell.\\\n",
    "You may add and import extra packages if needed, but only in this first cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1987b325",
   "metadata": {},
   "source": [
    "### Loading Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee78ae05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                            \n",
    "import pandas as pd                            \n",
    "\n",
    "import matplotlib.pyplot as plt                \n",
    "import seaborn as sns                          \n",
    "\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd0cde2",
   "metadata": {},
   "source": [
    "#### <font color='#fc7202'> Q1 (3 p): Estuarine Crocodiles \n",
    "Researchers measured head length and body length for 28 estuarine crocodiles to study their relationship.\n",
    "> Data: `hw3_data1.tsv`\n",
    "\n",
    "1. Load the dataset into a `pandas DataFrame` and create a scatterplot of head length (independent variable) and body length (dependent variable) with a linear regression line.\\\n",
    "   Briefly describe:\n",
    "   - whether the relationship appears linear or nonlinear, \n",
    "   - whether the association is positive or negative, and \n",
    "   - whether the association is weak, moderate, or strong.\n",
    "\n",
    "</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7d2a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7328f4b0",
   "metadata": {},
   "source": [
    "<font color='#00bf63'>*Your answer here!*</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de3708b",
   "metadata": {},
   "source": [
    "<font color='#fc7202'> 2. Compute the sample covariance between head length and body length, then compute the sample Pearson's correlation coefficient \\(*r*\\).\\\n",
    "Briefly comment on whether the sign and magnitude of these measures align with your description in **Q1.1**. </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493e8c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ea3cbc",
   "metadata": {},
   "source": [
    "<font color='#00bf63'>*Your answer here!*</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9713feaa",
   "metadata": {},
   "source": [
    "<font color='#fc7202'> 3. Find the equation of the linear regression line used to predict body length from head length (report both the estimated intercept and slope). </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b2944e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c99ee85",
   "metadata": {},
   "source": [
    "<font color='#00bf63'>*Your answer here!*</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2b90c7",
   "metadata": {},
   "source": [
    "<font color='#fc7202'> 4. Interpret the slope and the intercept of your regression line in context. If an interpretation is not appropriate, explain why. </font> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71084512",
   "metadata": {},
   "source": [
    "<font color='#00bf63'>*Your answer here!*</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac2fdca",
   "metadata": {},
   "source": [
    "<font color='#fc7202'> 5. Predict the body length of an estuarine crocodile with a head length of 55 cm in two ways:\n",
    "- using the regression formula directly, and \n",
    "- using the fitted model in Python. \n",
    "\n",
    "Report the results.\n",
    "\n",
    "</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c013ba08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25767d83",
   "metadata": {},
   "source": [
    "<font color='#00bf63'>*Your answer here!*</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d963f08f",
   "metadata": {},
   "source": [
    "#### <font color='#fc7202'> Q2 (5 p): Kyoto Cherry Blossoms\n",
    "In Practice Session 5 you examined whether peak bloom dates occurred earlier after 1880 than before 1880.  \n",
    "Data: https://ourworldindata.org/grapher/date-of-the-peak-cherry-tree-blossom-in-kyoto\n",
    "\n",
    "1. Create two linear regression models (separately for **pre-1880** and **post-1880**) with **peak bloom day-of-year** as the response and **calendar year** as the predictor.  \n",
    "\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1918b664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fe809c",
   "metadata": {},
   "source": [
    "<font color='#fc7202'> 2. Using the two models from **Q2.1**, compute the slopes and intercepts with 95% confidence intervals for each period, and report the coefficients of determination. </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e56b5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3473455e",
   "metadata": {},
   "source": [
    "<font color='#fc7202'> 3. Comment on the coefficients of determination for the two models. How much of the variability in peak bloom date is explained by the year of observation in each period? </font> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2bb750",
   "metadata": {},
   "source": [
    "<font color='#00bf63'>*Your answer here!*</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f953cb6",
   "metadata": {},
   "source": [
    "<font color='#fc7202'> 4. Which of the slopes are statistically different from zero at the 95% confidence level? </font> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe9df8d",
   "metadata": {},
   "source": [
    "<font color='#00bf63'>*Your answer here!*</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d60b39",
   "metadata": {},
   "source": [
    "<font color='#fc7202'> 5. At what rate (in days / year, with 95% confidence interval) is the day of full flowering of the cherry blossoms in Kyoto getting earlier in the year since 1880?\\\n",
    "Report the rate for pre-1880 and post-1880, then compare the two. </font> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41eb29ae",
   "metadata": {},
   "source": [
    "<font color='#00bf63'>*Your answer here!*</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7ed68c",
   "metadata": {},
   "source": [
    "<font color='#fc7202'> 6. Create plots for both datasets (pre-1880 and post-1880) showing the data with:\n",
    "- your fitted linear regression line, \n",
    "- 95% confidence intervals, and \n",
    "- 95% prediction intervals. \n",
    "\n",
    "</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb57f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d301439",
   "metadata": {},
   "source": [
    "#### <font color='#fc7202'> Q3 (5 p): Alprazolam\n",
    "Alprazolam is a widely used fast-acting tranquilizer, known for its strong anxiolytic effect. Its concentration is typically determined by chromatographic methods, which require calibration with standard solutions. Your calibration measurements are provided in `hw3_data2.tsv`.\n",
    "\n",
    "1. Load the dataset and plot the calibration curve (instrument response vs concentration).\\\n",
    "Describe the calibration curve - state clearly whether it is linear or not and characterize the pattern.\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee9635c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7428245c",
   "metadata": {},
   "source": [
    "<font color='#00bf63'>*Your answer here!*</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0853d5e",
   "metadata": {},
   "source": [
    "<font color='#fc7202'> 2. Identify the calibration’s linear range by visual inspection. Iteratively remove points that fall outside the putative linear region, re-plot after each change, and present the final set of retained points. Briefly document your workflow and rationale (which data points you removed and why).</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a2ed3e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52f5dbf",
   "metadata": {},
   "source": [
    "<font color='#00bf63'>*Your answer here!*</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061b4216",
   "metadata": {},
   "source": [
    "<font color='#fc7202'> 3. Fit a linear regression to your retained calibration points. Report the estimated slope and intercept (with 95% confidence intervals), relevant test statistics/*p*-values, R², and briefly interpret the results. Comment on whether the findings align with your expectations from the visual assessment.  \n",
    "</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e55a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877382c3",
   "metadata": {},
   "source": [
    "<font color='#00bf63'>*Your answer here!*</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e24b68",
   "metadata": {},
   "source": [
    "<font color='#fc7202'> 4. Add the fitted regression line to your scatterplot (you may include a confidence band) and describe any systematic deviations you observe. </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d0e98ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757ac25c",
   "metadata": {},
   "source": [
    "<font color='#00bf63'>*Your answer here!*</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3672380",
   "metadata": {},
   "source": [
    "<font color='#fc7202'> 5. Since the linear range was unknown to you, perform a residual analysis to assess linearity. Calculate the residuals (the difference between the observed/measured values and fitted signal values) and plot them against concentration. Describe the pattern you observe and explain what it indicates about the linearity of your calibration. Discuss how you should continue analysing your data based on these results - then carry out those steps (e.g., adjust the range, refit, and update diagnostics). </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d439b6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4c3e3e",
   "metadata": {},
   "source": [
    "<font color='#00bf63'>*Your answer here!*</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de3f84e",
   "metadata": {},
   "source": [
    "<font color='#fc7202'> 6. After finalizing the linear range, revisit the model summary to verify that all parameters are statistically significant. Make any necessary modifications, visualize the updated results, and clearly explain what you are doing and why. </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27273fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba32c80",
   "metadata": {},
   "source": [
    "<font color='#00bf63'>*Your answer here!*</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6859afbb",
   "metadata": {},
   "source": [
    "<font color='#fc7202'> 7. Using your finalized linear range, predict concentrations for the following sample responses and analyze the results: `75987, 12925, 289, 56`. Report the estimated concentrations, indicate whether each response lies within the reportable linear range, and justify any decisions about excluding or qualifying results.</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cfe1660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26b9c30",
   "metadata": {},
   "source": [
    "<font color='#00bf63'>*Your answer here!*</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0b744c",
   "metadata": {},
   "source": [
    "#### <font color='#fc7202'> Q4 (10 p): Plastic Composition\n",
    "You have been hired in a new materials development laboratory, where work is underway on creating a new type of plastic. The first prototype has been produced using a mixture of **10 substances**.\\\n",
    "Because the plastic is intended for high-temperature applications, it is crucial to know its melting temperature as precisely as possible.\\\n",
    "Experiments have already been conducted on **100 variations of this prototype plastic, each with slightly modified proportions of the 10 components**. For every variation, the melting temperature has been measured.\n",
    "\n",
    "The training data are provided as follows:\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f6f42be6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.551499</td>\n",
       "      <td>0.262372</td>\n",
       "      <td>0.889061</td>\n",
       "      <td>-0.422355</td>\n",
       "      <td>-0.660052</td>\n",
       "      <td>-0.078463</td>\n",
       "      <td>0.098498</td>\n",
       "      <td>0.401738</td>\n",
       "      <td>-0.561374</td>\n",
       "      <td>-0.309743</td>\n",
       "      <td>197.159444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.003090</td>\n",
       "      <td>1.121439</td>\n",
       "      <td>-1.237709</td>\n",
       "      <td>0.379204</td>\n",
       "      <td>-0.215026</td>\n",
       "      <td>-1.241808</td>\n",
       "      <td>-0.058320</td>\n",
       "      <td>0.708846</td>\n",
       "      <td>-0.587341</td>\n",
       "      <td>1.273576</td>\n",
       "      <td>197.277663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.980808</td>\n",
       "      <td>0.495378</td>\n",
       "      <td>0.851462</td>\n",
       "      <td>-1.568157</td>\n",
       "      <td>1.314776</td>\n",
       "      <td>-0.358950</td>\n",
       "      <td>-0.738867</td>\n",
       "      <td>-1.078135</td>\n",
       "      <td>-1.142376</td>\n",
       "      <td>0.389745</td>\n",
       "      <td>190.410029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.957068</td>\n",
       "      <td>0.403847</td>\n",
       "      <td>0.387052</td>\n",
       "      <td>-0.146839</td>\n",
       "      <td>1.719678</td>\n",
       "      <td>-1.213150</td>\n",
       "      <td>-1.411872</td>\n",
       "      <td>0.616580</td>\n",
       "      <td>1.176239</td>\n",
       "      <td>1.131221</td>\n",
       "      <td>191.235918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.337244</td>\n",
       "      <td>-0.539921</td>\n",
       "      <td>-1.389232</td>\n",
       "      <td>1.927250</td>\n",
       "      <td>-0.158450</td>\n",
       "      <td>-0.716476</td>\n",
       "      <td>0.183199</td>\n",
       "      <td>-0.349048</td>\n",
       "      <td>0.224777</td>\n",
       "      <td>-2.248594</td>\n",
       "      <td>187.256636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1        x2        x3        x4        x5        x6        x7  \\\n",
       "0 -1.551499  0.262372  0.889061 -0.422355 -0.660052 -0.078463  0.098498   \n",
       "1 -1.003090  1.121439 -1.237709  0.379204 -0.215026 -1.241808 -0.058320   \n",
       "2  0.980808  0.495378  0.851462 -1.568157  1.314776 -0.358950 -0.738867   \n",
       "3  3.957068  0.403847  0.387052 -0.146839  1.719678 -1.213150 -1.411872   \n",
       "4  1.337244 -0.539921 -1.389232  1.927250 -0.158450 -0.716476  0.183199   \n",
       "\n",
       "         x8        x9       x10           y  \n",
       "0  0.401738 -0.561374 -0.309743  197.159444  \n",
       "1  0.708846 -0.587341  1.273576  197.277663  \n",
       "2 -1.078135 -1.142376  0.389745  190.410029  \n",
       "3  0.616580  1.176239  1.131221  191.235918  \n",
       "4 -0.349048  0.224777 -2.248594  187.256636  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training = pd.read_csv('hw3_data3.tsv', sep='\\t')\n",
    "df_training.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b76420",
   "metadata": {},
   "source": [
    "<font color='#fc7202'> Each row in the dataset corresponds to one experiment. The columns `x1 … x10` show how much (in percent) the amounts of the ten components were adjusted, and the column `y` represents the melting temperature. \n",
    "\n",
    "After discussing with your colleagues, you conclude that a linear model is a reasonable choice for predicting the melting temperature. There is reason to believe that some components may have little or no effect, while others could influence the melting temperature to varying degrees - and potentially in opposite directions.\n",
    "\n",
    "As a first step, fit a linear regression model: \n",
    "\n",
    "</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "12d1fd24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.799</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.776</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   35.37</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 15 Oct 2025</td> <th>  Prob (F-statistic):</th> <td>8.39e-27</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:10:08</td>     <th>  Log-Likelihood:    </th> <td> -238.84</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   100</td>      <th>  AIC:               </th> <td>   499.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    89</td>      <th>  BIC:               </th> <td>   528.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    10</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>  188.9224</td> <td>    0.286</td> <td>  660.481</td> <td> 0.000</td> <td>  188.354</td> <td>  189.491</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>        <td>   -2.0678</td> <td>    0.280</td> <td>   -7.384</td> <td> 0.000</td> <td>   -2.624</td> <td>   -1.511</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>        <td>   -0.2465</td> <td>    0.293</td> <td>   -0.841</td> <td> 0.403</td> <td>   -0.829</td> <td>    0.336</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>        <td>    1.3297</td> <td>    0.319</td> <td>    4.174</td> <td> 0.000</td> <td>    0.697</td> <td>    1.963</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>        <td>    0.4935</td> <td>    0.324</td> <td>    1.525</td> <td> 0.131</td> <td>   -0.149</td> <td>    1.136</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>        <td>    1.4334</td> <td>    0.268</td> <td>    5.343</td> <td> 0.000</td> <td>    0.900</td> <td>    1.967</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>        <td>   -4.7050</td> <td>    0.337</td> <td>  -13.958</td> <td> 0.000</td> <td>   -5.375</td> <td>   -4.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>        <td>    0.5921</td> <td>    0.303</td> <td>    1.957</td> <td> 0.053</td> <td>   -0.009</td> <td>    1.193</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>        <td>    0.9040</td> <td>    0.285</td> <td>    3.176</td> <td> 0.002</td> <td>    0.339</td> <td>    1.469</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>        <td>   -0.9705</td> <td>    0.313</td> <td>   -3.103</td> <td> 0.003</td> <td>   -1.592</td> <td>   -0.349</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>       <td>    0.3306</td> <td>    0.266</td> <td>    1.241</td> <td> 0.218</td> <td>   -0.199</td> <td>    0.860</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.859</td> <th>  Durbin-Watson:     </th> <td>   2.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.395</td> <th>  Jarque-Bera (JB):  </th> <td>   1.745</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.225</td> <th>  Prob(JB):          </th> <td>   0.418</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.535</td> <th>  Cond. No.          </th> <td>    1.99</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &     0.799   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.776   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     35.37   \\\\\n",
       "\\textbf{Date:}             & Wed, 15 Oct 2025 & \\textbf{  Prob (F-statistic):} &  8.39e-27   \\\\\n",
       "\\textbf{Time:}             &     21:10:08     & \\textbf{  Log-Likelihood:    } &   -238.84   \\\\\n",
       "\\textbf{No. Observations:} &         100      & \\textbf{  AIC:               } &     499.7   \\\\\n",
       "\\textbf{Df Residuals:}     &          89      & \\textbf{  BIC:               } &     528.3   \\\\\n",
       "\\textbf{Df Model:}         &          10      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                   & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept} &     188.9224  &        0.286     &   660.481  &         0.000        &      188.354    &      189.491     \\\\\n",
       "\\textbf{x1}        &      -2.0678  &        0.280     &    -7.384  &         0.000        &       -2.624    &       -1.511     \\\\\n",
       "\\textbf{x2}        &      -0.2465  &        0.293     &    -0.841  &         0.403        &       -0.829    &        0.336     \\\\\n",
       "\\textbf{x3}        &       1.3297  &        0.319     &     4.174  &         0.000        &        0.697    &        1.963     \\\\\n",
       "\\textbf{x4}        &       0.4935  &        0.324     &     1.525  &         0.131        &       -0.149    &        1.136     \\\\\n",
       "\\textbf{x5}        &       1.4334  &        0.268     &     5.343  &         0.000        &        0.900    &        1.967     \\\\\n",
       "\\textbf{x6}        &      -4.7050  &        0.337     &   -13.958  &         0.000        &       -5.375    &       -4.035     \\\\\n",
       "\\textbf{x7}        &       0.5921  &        0.303     &     1.957  &         0.053        &       -0.009    &        1.193     \\\\\n",
       "\\textbf{x8}        &       0.9040  &        0.285     &     3.176  &         0.002        &        0.339    &        1.469     \\\\\n",
       "\\textbf{x9}        &      -0.9705  &        0.313     &    -3.103  &         0.003        &       -1.592    &       -0.349     \\\\\n",
       "\\textbf{x10}       &       0.3306  &        0.266     &     1.241  &         0.218        &       -0.199    &        0.860     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  1.859 & \\textbf{  Durbin-Watson:     } &    2.000  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.395 & \\textbf{  Jarque-Bera (JB):  } &    1.745  \\\\\n",
       "\\textbf{Skew:}          & -0.225 & \\textbf{  Prob(JB):          } &    0.418  \\\\\n",
       "\\textbf{Kurtosis:}      &  2.535 & \\textbf{  Cond. No.          } &     1.99  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.799\n",
       "Model:                            OLS   Adj. R-squared:                  0.776\n",
       "Method:                 Least Squares   F-statistic:                     35.37\n",
       "Date:                Wed, 15 Oct 2025   Prob (F-statistic):           8.39e-27\n",
       "Time:                        21:10:08   Log-Likelihood:                -238.84\n",
       "No. Observations:                 100   AIC:                             499.7\n",
       "Df Residuals:                      89   BIC:                             528.3\n",
       "Df Model:                          10                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept    188.9224      0.286    660.481      0.000     188.354     189.491\n",
       "x1            -2.0678      0.280     -7.384      0.000      -2.624      -1.511\n",
       "x2            -0.2465      0.293     -0.841      0.403      -0.829       0.336\n",
       "x3             1.3297      0.319      4.174      0.000       0.697       1.963\n",
       "x4             0.4935      0.324      1.525      0.131      -0.149       1.136\n",
       "x5             1.4334      0.268      5.343      0.000       0.900       1.967\n",
       "x6            -4.7050      0.337    -13.958      0.000      -5.375      -4.035\n",
       "x7             0.5921      0.303      1.957      0.053      -0.009       1.193\n",
       "x8             0.9040      0.285      3.176      0.002       0.339       1.469\n",
       "x9            -0.9705      0.313     -3.103      0.003      -1.592      -0.349\n",
       "x10            0.3306      0.266      1.241      0.218      -0.199       0.860\n",
       "==============================================================================\n",
       "Omnibus:                        1.859   Durbin-Watson:                   2.000\n",
       "Prob(Omnibus):                  0.395   Jarque-Bera (JB):                1.745\n",
       "Skew:                          -0.225   Prob(JB):                        0.418\n",
       "Kurtosis:                       2.535   Cond. No.                         1.99\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preliminary = smf.ols('y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10 + 1', df_training)\n",
    "model_preliminary = model_preliminary.fit()\n",
    "model_preliminary.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e124f221",
   "metadata": {},
   "source": [
    "<font color='#fc7202'> Since this task is highly important, you decide to examine how linear models typically behave with this type of data before applying the fitted model directly.\n",
    "\n",
    "To do so, you will create a synthetic linear model and generate corresponding synthetic data to test how well a model can be recovered from such data.\n",
    "\n",
    "After discussing with the materials scientists, you conclude that approximately half of the coefficients (`weights`) are likely to be zero, while the remaining coefficients follow a normal distribution $N(0, 2^2)$.\\\n",
    "Based on this reasoning, you proceed to construct the model as follows: </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5bb6f95c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.75879595  0.          0.1320614   2.25448241  0.         -1.71858493\n",
      "  0.73750157 -1.9177652   0.         -0.        ]\n",
      "[198.15137636]\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.default_rng(42)\n",
    "k = 10\n",
    "weights = rng.binomial(n=1, p=0.5, size=k) * rng.normal(loc=0, scale=2, size=k)\n",
    "intercept = rng.normal(loc=200, scale=10, size=1)\n",
    "print(weights)\n",
    "print(intercept)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a445341",
   "metadata": {},
   "source": [
    "<font color='#fc7202'> To generate the data, you use the same protocol as in the real experiments: all changes in component quantities are drawn from the distribution\n",
    "$N(0, 1)$.\\\n",
    "You also include measurement noise in the melting temperature, assuming that the measurement errors follow a normal distribution with a mean of 0 and a standard deviation of 3 ($N(0, 3^2)$).\n",
    "\n",
    "Based on this, the data are generated as follows:</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "01952cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.304717</td>\n",
       "      <td>-1.039984</td>\n",
       "      <td>0.750451</td>\n",
       "      <td>0.940565</td>\n",
       "      <td>-1.951035</td>\n",
       "      <td>-1.302180</td>\n",
       "      <td>0.127840</td>\n",
       "      <td>-0.316243</td>\n",
       "      <td>-0.016801</td>\n",
       "      <td>-0.853044</td>\n",
       "      <td>202.489718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.879398</td>\n",
       "      <td>0.777792</td>\n",
       "      <td>0.066031</td>\n",
       "      <td>1.127241</td>\n",
       "      <td>0.467509</td>\n",
       "      <td>-0.859292</td>\n",
       "      <td>0.368751</td>\n",
       "      <td>-0.958883</td>\n",
       "      <td>0.878450</td>\n",
       "      <td>-0.049926</td>\n",
       "      <td>203.838123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.184862</td>\n",
       "      <td>-0.680930</td>\n",
       "      <td>1.222541</td>\n",
       "      <td>-0.154529</td>\n",
       "      <td>-0.428328</td>\n",
       "      <td>-0.352134</td>\n",
       "      <td>0.532309</td>\n",
       "      <td>0.365444</td>\n",
       "      <td>0.412733</td>\n",
       "      <td>0.430821</td>\n",
       "      <td>199.238252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.141648</td>\n",
       "      <td>-0.406415</td>\n",
       "      <td>-0.512243</td>\n",
       "      <td>-0.813773</td>\n",
       "      <td>0.615979</td>\n",
       "      <td>1.128972</td>\n",
       "      <td>-0.113947</td>\n",
       "      <td>-0.840156</td>\n",
       "      <td>-0.824481</td>\n",
       "      <td>0.650593</td>\n",
       "      <td>200.358329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.743254</td>\n",
       "      <td>0.543154</td>\n",
       "      <td>-0.665510</td>\n",
       "      <td>0.232161</td>\n",
       "      <td>0.116686</td>\n",
       "      <td>0.218689</td>\n",
       "      <td>0.871429</td>\n",
       "      <td>0.223596</td>\n",
       "      <td>0.678914</td>\n",
       "      <td>0.067579</td>\n",
       "      <td>195.517791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>-1.723463</td>\n",
       "      <td>0.451769</td>\n",
       "      <td>0.477529</td>\n",
       "      <td>-1.162429</td>\n",
       "      <td>-0.712102</td>\n",
       "      <td>1.370541</td>\n",
       "      <td>-0.484030</td>\n",
       "      <td>2.242920</td>\n",
       "      <td>-0.001920</td>\n",
       "      <td>0.408036</td>\n",
       "      <td>187.902851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1.616874</td>\n",
       "      <td>0.131027</td>\n",
       "      <td>-1.002344</td>\n",
       "      <td>-0.109727</td>\n",
       "      <td>-0.035611</td>\n",
       "      <td>-1.364742</td>\n",
       "      <td>-0.255832</td>\n",
       "      <td>-0.742192</td>\n",
       "      <td>0.924358</td>\n",
       "      <td>0.034612</td>\n",
       "      <td>206.807945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-0.282796</td>\n",
       "      <td>-0.106182</td>\n",
       "      <td>0.223122</td>\n",
       "      <td>0.616814</td>\n",
       "      <td>-0.999712</td>\n",
       "      <td>-1.041588</td>\n",
       "      <td>1.104679</td>\n",
       "      <td>-0.412337</td>\n",
       "      <td>-1.416842</td>\n",
       "      <td>0.443813</td>\n",
       "      <td>200.056004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.463370</td>\n",
       "      <td>-1.530715</td>\n",
       "      <td>0.229482</td>\n",
       "      <td>0.735583</td>\n",
       "      <td>0.374386</td>\n",
       "      <td>0.631981</td>\n",
       "      <td>-1.404269</td>\n",
       "      <td>0.331040</td>\n",
       "      <td>-0.302620</td>\n",
       "      <td>-0.482790</td>\n",
       "      <td>192.473960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.870556</td>\n",
       "      <td>1.479275</td>\n",
       "      <td>1.794370</td>\n",
       "      <td>1.314808</td>\n",
       "      <td>-0.109734</td>\n",
       "      <td>0.352720</td>\n",
       "      <td>0.766823</td>\n",
       "      <td>0.121178</td>\n",
       "      <td>0.130764</td>\n",
       "      <td>0.823753</td>\n",
       "      <td>207.241126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          x1        x2        x3        x4        x5        x6        x7  \\\n",
       "0   0.304717 -1.039984  0.750451  0.940565 -1.951035 -1.302180  0.127840   \n",
       "1   0.879398  0.777792  0.066031  1.127241  0.467509 -0.859292  0.368751   \n",
       "2  -0.184862 -0.680930  1.222541 -0.154529 -0.428328 -0.352134  0.532309   \n",
       "3   2.141648 -0.406415 -0.512243 -0.813773  0.615979  1.128972 -0.113947   \n",
       "4   0.743254  0.543154 -0.665510  0.232161  0.116686  0.218689  0.871429   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "95 -1.723463  0.451769  0.477529 -1.162429 -0.712102  1.370541 -0.484030   \n",
       "96  1.616874  0.131027 -1.002344 -0.109727 -0.035611 -1.364742 -0.255832   \n",
       "97 -0.282796 -0.106182  0.223122  0.616814 -0.999712 -1.041588  1.104679   \n",
       "98  0.463370 -1.530715  0.229482  0.735583  0.374386  0.631981 -1.404269   \n",
       "99  0.870556  1.479275  1.794370  1.314808 -0.109734  0.352720  0.766823   \n",
       "\n",
       "          x8        x9       x10           y  \n",
       "0  -0.316243 -0.016801 -0.853044  202.489718  \n",
       "1  -0.958883  0.878450 -0.049926  203.838123  \n",
       "2   0.365444  0.412733  0.430821  199.238252  \n",
       "3  -0.840156 -0.824481  0.650593  200.358329  \n",
       "4   0.223596  0.678914  0.067579  195.517791  \n",
       "..       ...       ...       ...         ...  \n",
       "95  2.242920 -0.001920  0.408036  187.902851  \n",
       "96 -0.742192  0.924358  0.034612  206.807945  \n",
       "97 -0.412337 -1.416842  0.443813  200.056004  \n",
       "98  0.331040 -0.302620 -0.482790  192.473960  \n",
       "99  0.121178  0.130764  0.823753  207.241126  \n",
       "\n",
       "[100 rows x 11 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = np.random.default_rng(42)\n",
    "\n",
    "n_training = 100\n",
    "n_testing = 100\n",
    "n = n_training + n_testing\n",
    "\n",
    "x = rng.normal(0, 1, size=(n,k))\n",
    "noise = rng.normal(0, 3, size=n)\n",
    "y = np.sum(weights*x, axis=1) + intercept + noise\n",
    "\n",
    "data = pd.DataFrame(x)\n",
    "data.columns = [f'x{i}' for i in range(1, 11)]\n",
    "data['y'] = y\n",
    "generated_training = data.iloc[:n_training, :]\n",
    "generated_testing_x = data.iloc[n_training:, :k]\n",
    "generated_testing_y = y[n_training:]\n",
    "generated_training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7779e6af",
   "metadata": {},
   "source": [
    "<font color='#fc7202'>1. Before moving to more complex models, fit a constant linear model to the synthetic training data (`generated_training`) using the formula `y ~ 1`. Compute the `RMSE` on the test set (`generated_testing_x`, `generated_testing_y`) and report it.\n",
    "\n",
    "*Hint:* Use the fitted model’s `.predict(...)` on `generated_testing_x`. Make sure that the model is trained on the **synthetic training data**, not on the real dataset or the test set.\n",
    "</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e3d034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e3a25c",
   "metadata": {},
   "source": [
    "<font color='#00bf63'>*Your answer here!*</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f38b6d",
   "metadata": {},
   "source": [
    "<font color='#fc7202'>2. Fit a linear model on `generated_training` that includes all features `x1, …, x10`. Output the model’s results table using `.summary()`. Then compute the `RMSE` on test set using `generated_testing_x` and `generated_testing_y`, and report it. </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd42a37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510e702b",
   "metadata": {},
   "source": [
    "<font color='#00bf63'>*Your answer here!*</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511f7a9c",
   "metadata": {},
   "source": [
    "<font color='#fc7202'>3. From the **Q4.2** summary, pick 3-7 features you believe are most important and exclude the others. Do not refit the model.\\\n",
    "Instead:\n",
    "- Make a copy of the test data (`generated_testing_x`).\n",
    "- Set the excluded features’ columns to 0 in this copy.\n",
    "- Use the same fitted model from **Q4.2** to predict on this modified test set, then compute the RMSE against `generated_testing_y`.\n",
    "\n",
    "Explain why you kept/removed each feature, report the RMSE, and compare with previous models (better or worse?)  </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cd258d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f152b12a",
   "metadata": {},
   "source": [
    "<font color='#00bf63'>*Your answer here!*</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74481c0e",
   "metadata": {},
   "source": [
    "<font color='#fc7202'>4. Fit a linear model on `generated_training` using only the features you retained in **Q4.3**. Output the results table with `.summary()`. Compute the RMSE on the test set (using `generated_testing_x` and `generated_testing_y`) and compare it to the RMSE from **Q4.3**. Did it improve? Explain why or why not. </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b688ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99d575a",
   "metadata": {},
   "source": [
    "<font color='#00bf63'>*Your answer here!*</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd65877",
   "metadata": {},
   "source": [
    "<font color='#fc7202'>5. Using the **Q4.4** summary, identify the least important feature. Fit a new linear model on `generated_training` without that feature (keep all the other features exactly as in **Q4.4**). Compute the RMSE on the test set (using `generated_testing_x` and `generated_testing_y`) and compare it to the RMSE from **Q4.4**. Did it improve? Briefly explain why or why not. </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abc6f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0b6252",
   "metadata": {},
   "source": [
    "<font color='#00bf63'>*Your answer here!*</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28a3980",
   "metadata": {},
   "source": [
    "<font color='#fc7202'>6. Using the **Q4.2** summary, choose one additional feature to add to the **Q4.4** model. Fit a new linear model on `generated_training` that includes this added feature (keep all other features the same as in **Q4.4**). Compute the RMSE on the test set (using `generated_testing_x` and `generated_testing_y`) and compare it to the RMSE from **Q4.4**. Did it improve? Briefly explain why or why not. </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27398e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9868a18",
   "metadata": {},
   "source": [
    "<font color='#00bf63'>*Your answer here!*</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d958348c",
   "metadata": {},
   "source": [
    "<font color='#fc7202'>7. Analyze how the RMSE results from **Q4.2**, **Q4.4**, **Q4.5**, and **Q4.6** depend on the set of features used for fitting, taking into account which coefficients are truly nonzero in the `weights` array.\n",
    "Discuss whether the full-model summary in **Q4.2** allows you to determine which coefficients are likely different from zero. Justify your answer using the reported estimates, standard errors, confidence intervals, or *p*-values. </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbea75e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0509ead8",
   "metadata": {},
   "source": [
    "<font color='#00bf63'>*Your answer here!*</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64149fca",
   "metadata": {},
   "source": [
    "<font color='#fc7202'>8. Now that the synthetic data have been analyzed, return to the original task: determine which component amounts affect the plastic’s melting temperature and by how much.\n",
    "\n",
    "- Fit a linear model using all predictors (`x1 … x10`) on `df_training`.\n",
    "- Inspect the model summary and decide which predictors appear important for predicting melting temperature, and which do not. Explain your decision.\n",
    "- Fit a new linear model on `df_training` using only your selected predictors and report its summary.\n",
    "- Test data are in `hw3_data4.tsv`. Compute the RMSE on these test data for **(a)** the all-predictors model and **(b)** the selected-predictors model. Which performs better, and why?\n",
    "\n",
    "</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2847c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17ebe9e",
   "metadata": {},
   "source": [
    "<font color='#00bf63'>*Your answer here!*</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9716e22",
   "metadata": {},
   "source": [
    "<font color='#fc7202'>9. We continue with the previous topic, now focusing on parameter interval estimates (confidence intervals). Your goal is to measure, on the synthetic model, how often the true parameter values fall inside the confidence intervals obtained from refitted models.\n",
    "\n",
    "- Generate 1,000 synthetic datasets in the same way as at the start of **Q4**.\n",
    "    Use a different random `seed` for each run (e.g., `np.random.default_rng(seed)`), but keep the true parameters - `weights` and `intercept` - fixed across all simulations.\n",
    "- For each dataset, fit a linear model with all 10 parameters. \n",
    "- Compute confidence intervals for all parameters using the fitted model’s `.conf_int()` method.\n",
    "- Compute the empirical coverage:\n",
    "    For each of the **11** parameters (**10 coefficients/weights plus the intercept**), determine the percentage of models - out of the 1,000 fits - in which the true value falls within its 95% confidence interval.\n",
    "    Comment on whether these percentages are close to 95%, and explain why or why not. \n",
    "    \n",
    "</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d091ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18be8677",
   "metadata": {},
   "source": [
    "<font color='#00bf63'>*Your answer here!*</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09806ab",
   "metadata": {},
   "source": [
    "<font color='#fc7202'>10. Repeat the same experiment as in **Q4.9**, but this time determine the percentage of datasets in which all parameters simultaneously fall within their respective confidence intervals.\n",
    "\n",
    "Then adjust the confidence level by changing the `alpha` value in the model’s `.conf_int(alpha=...)` method until the overall percentage is approximately **95%**.\n",
    "Finally, report the value of `alpha` that achieves this.\n",
    "\n",
    "*Hint:* When testing different values of `alpha`, you can first use 100 datasets instead of 1,000 to make the computation faster. Once your `alpha` value is close to the correct level, rerun the experiment with 1,000 datasets for the final estimate. </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6fb7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8004eab",
   "metadata": {},
   "source": [
    "<font color='#00bf63'>*Your answer here!*</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5a408f",
   "metadata": {},
   "source": [
    "<font color='#fc7202'>11. Fit a linear model with all the parameters on `df_training`. Compute parameter confidence intervals using the `alpha` you determined in **Q4.10**. Then read the true parameters from `hw3_data5.tsv` and check whether all parameters simultaneously fall within their respective intervals. </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c46e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9019e5b7",
   "metadata": {},
   "source": [
    "<font color='#00bf63'>*Your answer here!*</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0c777e",
   "metadata": {},
   "source": [
    "## Before you submit\n",
    "\n",
    "**Don’t forget:**\n",
    "\n",
    "Please restart the kernel and run all cells from top to bottom to ensure your notebook works correctly.\n",
    "1. In Jupyter Notebook or JupyterLab:\n",
    "   Go to the menu bar and select:\n",
    "   - `Kernel → Restart & Run All`\n",
    "2. In Visual Studio Code (VS Code):\n",
    "   - Click the `Restart Kernel` button `(↻)` (on the toolbar).\n",
    "   - Then click `Run All` `(▶▶)` to execute all cells in order.\n",
    "Make sure the notebook runs **end-to-end without errors**.\\\n",
    "If a cell still produces an error that you can’t resolve, simply **comment out that section** so the remaining cells can execute without interruption.\n",
    "\n",
    "**Time spent**\n",
    "\n",
    "Please record roughly how long you worked on this assignment:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff4bf38",
   "metadata": {},
   "source": [
    "<font color='#00bf63'>*Total time spent: XXXXX h*</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b230fe77",
   "metadata": {},
   "source": [
    "**Comments (optional feedback)**\n",
    "\n",
    "Here, please, leave your comments regarding the homework, possibly answering the following questions:\n",
    "- Was it too hard/easy for you?\n",
    "- What would you suggest to add or remove?\n",
    "- Anything else you would like to tell us?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcec6b7",
   "metadata": {},
   "source": [
    "<font color='#00bf63'>*Your feedback*</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8040bd",
   "metadata": {},
   "source": [
    "Excellent work making it all the way through!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
