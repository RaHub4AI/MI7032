{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e728ea0b",
   "metadata": {},
   "source": [
    "# Practice Session 3: From Distributions to Statistical Thinking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a70f569",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import skew, kurtosis, shapiro, kstest, norm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ipywidgets import interact, FloatSlider\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efce511",
   "metadata": {},
   "source": [
    "## Part 1: Revisiting the Wine Quality Dataset\n",
    "\n",
    "Yesterday, we began exploring the **Wine Quality dataset** and learned how to visualize and analyze distributions.  \n",
    "Before we move further, there are two very important points to revisit.\n",
    "\n",
    "Let’s take another look at the dataset and recall how summary statistics are reported in Python.  \n",
    "When we use the **`.describe()`** method, it automatically provides key descriptive measures such as the\\\n",
    "**mean**, **standard deviation**, **minimum**, **maximum**, and **quartiles** for each numeric variable.\n",
    "\n",
    "However, not all functions in Python compute these statistics in exactly the same way.  \n",
    "Today, we’ll check this by comparing different implementations of the **standard deviation**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07e4c26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Wine Quality dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\"\n",
    "wine_data = pd.read_csv(url, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5334bcd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.319637</td>\n",
       "      <td>0.527821</td>\n",
       "      <td>0.270976</td>\n",
       "      <td>2.538806</td>\n",
       "      <td>0.087467</td>\n",
       "      <td>15.874922</td>\n",
       "      <td>46.467792</td>\n",
       "      <td>0.996747</td>\n",
       "      <td>3.311113</td>\n",
       "      <td>0.658149</td>\n",
       "      <td>10.422983</td>\n",
       "      <td>5.636023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.741096</td>\n",
       "      <td>0.179060</td>\n",
       "      <td>0.194801</td>\n",
       "      <td>1.409928</td>\n",
       "      <td>0.047065</td>\n",
       "      <td>10.460157</td>\n",
       "      <td>32.895324</td>\n",
       "      <td>0.001887</td>\n",
       "      <td>0.154386</td>\n",
       "      <td>0.169507</td>\n",
       "      <td>1.065668</td>\n",
       "      <td>0.807569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.600000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.990070</td>\n",
       "      <td>2.740000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.100000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.995600</td>\n",
       "      <td>3.210000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.079000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.996750</td>\n",
       "      <td>3.310000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.200000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.997835</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.900000</td>\n",
       "      <td>1.580000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>0.611000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>1.003690</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.900000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "count    1599.000000       1599.000000  1599.000000     1599.000000   \n",
       "mean        8.319637          0.527821     0.270976        2.538806   \n",
       "std         1.741096          0.179060     0.194801        1.409928   \n",
       "min         4.600000          0.120000     0.000000        0.900000   \n",
       "25%         7.100000          0.390000     0.090000        1.900000   \n",
       "50%         7.900000          0.520000     0.260000        2.200000   \n",
       "75%         9.200000          0.640000     0.420000        2.600000   \n",
       "max        15.900000          1.580000     1.000000       15.500000   \n",
       "\n",
       "         chlorides  free sulfur dioxide  total sulfur dioxide      density  \\\n",
       "count  1599.000000          1599.000000           1599.000000  1599.000000   \n",
       "mean      0.087467            15.874922             46.467792     0.996747   \n",
       "std       0.047065            10.460157             32.895324     0.001887   \n",
       "min       0.012000             1.000000              6.000000     0.990070   \n",
       "25%       0.070000             7.000000             22.000000     0.995600   \n",
       "50%       0.079000            14.000000             38.000000     0.996750   \n",
       "75%       0.090000            21.000000             62.000000     0.997835   \n",
       "max       0.611000            72.000000            289.000000     1.003690   \n",
       "\n",
       "                pH    sulphates      alcohol      quality  \n",
       "count  1599.000000  1599.000000  1599.000000  1599.000000  \n",
       "mean      3.311113     0.658149    10.422983     5.636023  \n",
       "std       0.154386     0.169507     1.065668     0.807569  \n",
       "min       2.740000     0.330000     8.400000     3.000000  \n",
       "25%       3.210000     0.550000     9.500000     5.000000  \n",
       "50%       3.310000     0.620000    10.200000     6.000000  \n",
       "75%       3.400000     0.730000    11.100000     6.000000  \n",
       "max       4.010000     2.000000    14.900000     8.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950cda79",
   "metadata": {},
   "source": [
    "#### <font color='#fc7202'> Task 1: </font>  \n",
    "Using the **Wine Quality dataset**, calculate the **standard deviation** for all numeric variables with two different functions:\n",
    "\n",
    "1. **`numpy.std()`**  \n",
    "2. **`scipy.stats.tstd()`**\n",
    "\n",
    "Then, compare the results with the standard deviation values shown in the `.describe()` summary table.  \n",
    "Are all the results identical? If not, think about why they differ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ecd973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528432cd",
   "metadata": {},
   "source": [
    "#### Comparing Variability Across Variables  \n",
    "\n",
    "As we can see, the standard deviations vary quite a lot between the variables.  \n",
    "However, since each variable may have a **different mean and scale**, directly comparing their standard deviations isn’t very meaningful.  \n",
    "\n",
    "To make the comparison fair, we can compute the **coefficient of variation (CV)**, which expresses the **standard deviation relative to the mean**:\n",
    "\\begin{equation} \\text {CV} = \\frac{s}{\\bar{x}} \\end{equation}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a362c67",
   "metadata": {},
   "source": [
    "#### <font color='#fc7202'> Task 2: </font>  \n",
    "Compute the **coefficient of variation** for each numeric variable in the dataset.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7120782e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd87cf6",
   "metadata": {},
   "source": [
    "#### Revisiting the Kolgomorov-Smirnov (K-S) test\n",
    "\n",
    "Yesterday we saw that we can use the **Kolmogorov–Smirnov (K–S) test** to check whether our data come from a normal distribution.  \n",
    "This test compares the **empirical cumulative distribution function (ECDF)** of the data with the **theoretical cumulative distribution function (CDF)** of the normal distribution.\n",
    "\n",
    "Before we look deeper into the test, let’s first understand what the **CDF** actually represents.\n",
    "\n",
    "**The Probability Density Function (PDF)**\n",
    "\n",
    "The **PDF** describes how probability is *distributed* across a continuous variable.  \n",
    "It shows where the values of a variable are **most likely to occur**, but the **height of the curve** itself is *not* a probability.\n",
    "\n",
    "> - For continuous data (like height), the probability of any **exact value** (e.g., exactly 165.000... cm) is **zero**.\n",
    "> - Instead, probability is found by the **area under the curve** between two points.  \n",
    ">   For example:\n",
    ">   \\begin{equation} P(160 < X < 170) = \\int_{160}^{170} f(x)\\,dx \\end{equation}\n",
    ">   where $f(x)$ is the PDF.\n",
    "\n",
    "Because all probabilities together must add up to 1,  \n",
    "\\begin{equation} \\int_{-\\infty}^{\\infty} f(x)\\,dx = 1 \\end{equation}\n",
    "\n",
    "\n",
    "**The Cumulative Distribution Function (CDF)**\n",
    "\n",
    "The **CDF**, usually written as $F(x)$, tells us **the probability that a value is less than or equal to x**:\n",
    "\\begin{equation} F(x) = P(X \\le x) = \\int_{-\\infty}^{x} f(t)\\,dt \\end{equation}\n",
    "So, the CDF is literally the **accumulated area under the PDF** up to the point $x$.\n",
    "\n",
    "- The *y*-axis of the CDF shows this cumulative probability - it always ranges from 0 to 1.\n",
    "- At very small $x$, almost no area is accumulated, so $F(x) \\approx 0$.\n",
    "- Around the middle (for example, the mean of a normal distribution), $F(x)$ (might be) is around 0.5, meaning half the total probability lies below that point.\n",
    "- As $x$ grows large, the entire area is included, and $F(x) \\to 1$.\n",
    "\n",
    "> - The PDF is the **derivative** of the CDF:\n",
    ">   \\begin{equation} f(x) = \\frac{dF(x)}{dx} \\end{equation}\n",
    "> - The CDF is the **integral** of the PDF:\n",
    ">   \\begin{equation} F(x) = \\int_{-\\infty}^{x} f(t)\\,dt \\end{equation}\n",
    "  \n",
    "\n",
    "Graphically:\n",
    "- The PDF shows how *dense* probability is at each point.\n",
    "- The CDF shows how that density *accumulates* as we move from left to right.\n",
    "\n",
    "In the cell below, you can interactively change the **threshold** and see, how the area under the PDF up to that threshold corresponds to the value of the CDF at that same point.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf4e5746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "340f45a1d7f747dca1c6501be2a4cdb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='threshold', max=4.0, min=-4.0), Output()), _dom_clas…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "def pdf_cdf_threshold_standard(thresh=0.0):\n",
    "    # Fixed standard normal distribution\n",
    "    mu, sigma = 0.0, 1.0\n",
    "    x = np.linspace(-4, 4, 1000)\n",
    "    pdf = norm.pdf(x, loc=mu, scale=sigma)\n",
    "    cdf = norm.cdf(x, loc=mu, scale=sigma)\n",
    "    F_t = norm.cdf(thresh, loc=mu, scale=sigma)\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "\n",
    "    # PDF with shaded area up to threshold\n",
    "    ax1 = plt.subplot(2,1,1)\n",
    "    ax1.plot(x, pdf, color= \"#fc7202\", label=\"PDF (standard normal)\")\n",
    "    mask = x <= thresh\n",
    "    ax1.fill_between(x[mask], pdf[mask], alpha=0.3, color=\"#fc7202\", label=f\"Area up to threshold = {F_t:.4f}\")\n",
    "    ax1.axvline(thresh, linestyle=\"--\", color=\"#570a6d\", label=f\"threshold = {thresh:.2f}\")\n",
    "    ax1.set_xlabel(\"x\")\n",
    "    ax1.set_ylabel(\"Density\")\n",
    "    ax1.legend(loc=\"best\")\n",
    "\n",
    "    # --- Bottom: CDF with marker at threshold ---\n",
    "    ax2 = plt.subplot(2,1,2)\n",
    "    ax2.plot(x, cdf, color= \"#fc7202\", label=\"CDF (standard normal)\")\n",
    "    ax2.axvline(thresh, linestyle=\"--\", color=\"#570a6d\")\n",
    "    ax2.axhline(F_t, linestyle=\"--\", color=\"#570a6d\")\n",
    "    ax2.plot([thresh], [F_t], marker=\"o\", color=\"#570a6d\")\n",
    "    ax2.set_title(f\"CDF; F(threshold) = {F_t:.4f}\")\n",
    "    ax2.set_xlabel(\"x\")\n",
    "    ax2.set_ylabel(\"F(x)\")\n",
    "    ax2.legend(loc=\"best\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "interact(\n",
    "    pdf_cdf_threshold_standard,\n",
    "    thresh=FloatSlider(value=0.0, min=-4, max=4, step=0.1, description=\"threshold\"),);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa68d1d",
   "metadata": {},
   "source": [
    "Now that we understand what the CDF is, we can connect it to the Kolmogorov–Smirnov (K–S) test - a nonparametric test that compares two CDFs.\n",
    "\n",
    "**What the K-S test does?**\\\n",
    "The idea of the test is simple:\n",
    "- It compares the **empirical CDF** of your data (based on observed values)  \n",
    "  with a **theoretical CDF** (for example, the CDF of a normal distribution).\n",
    "- It then measures the **largest vertical distance (D)** between these two curves.\n",
    "\n",
    "If this maximum difference $D$ is large, it suggests that the sample does **not** come from the specified distribution.\n",
    "\n",
    "**Key assumption:** The theoretical CDF you compare against must be **fully specified**.  \n",
    "That is, its parameters (like mean and standard deviation) should be known **before** looking at your data.\n",
    "\n",
    "**The main problem:** In practice, when we test for *normality*, we almost never know the true mean and standard deviation of the population.  \n",
    "We usually **estimate them from the same sample** that we are testing, for example:\n",
    "```python\n",
    "stat, p = kstest(data, 'norm', args=(np.mean(data), np.std(data)))\n",
    "```\n",
    "This is a common approach, but it changes the distribution of the test statistic under the null hypothesis.\n",
    "In other words, the standard K-S critical values are no longer valid when we plug in estimated parameters.\n",
    "This means that the regular K-S test becomes too strict (conservative), meaning, it might reject normality less often than it should even when the data are not perfectly normal.\n",
    "\n",
    "In our case, this leads to two practical approaches for performing the K-S test:\n",
    "1. Pass parameters (mean and standard deviation) via `args`  \n",
    "2. Standardize the data first\n",
    "> Data standardization transforms a variable into *z*-scores (standard scores).\\\n",
    "> When the population mean and the population standard deviation are unknown, the standard score may be estimated by using\\\n",
    "> the sample mean ($\\bar{x}$) and sample standard deviation ($s$) as estimates of the population values.\\\n",
    "> In these cases, the *z*-score is given by:\n",
    ">\n",
    ">   \\begin{equation} z = \\frac{x - \\bar{x}}{s} \\end{equation}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb9cca5",
   "metadata": {},
   "source": [
    "#### <font color='#fc7202'>Task 3:</font>  \n",
    "1. Standardize all numeric variables and store them in a new DataFrame called `wine_data_standard`.  \n",
    "2. Visualize the variable `density` before and after standardization to see that the shape of the distribution stays the same, while the center and scale change.  \n",
    "3. Run the Kolmogorov–Smirnov test for each numeric variable in two ways:  \n",
    "   - On the **raw data**, using `args=(mean, sd)` to specify the parameters.  \n",
    "   - On the **standardized data**, comparing directly against `'norm'` (the standard normal distribution).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e3e73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3baacbe8",
   "metadata": {},
   "source": [
    "## Part 2: Simulating Continuous Data\n",
    "\n",
    "Yesterday, we simulated data for a **discrete random variable** (the roll of a die).  \n",
    "When we rolled the die only a few times (for example, 7 rolls), the results looked noisy and irregular,  \n",
    "and the underlying distribution (where all outcomes are equally likely) was not yet visible.  \n",
    "As we increased the number of rolls, however, the distribution began to *stabilize* and approach the expected uniform shape.\n",
    "\n",
    "Today, we’ll do something very similar, but this time for a **continuous random variable**.  \n",
    "Instead of discrete dice outcomes, we’ll simulate measurements that follow a **normal distribution**,  \n",
    "with a **mean of 10.5** and a **standard deviation of 1.8**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb56bf6",
   "metadata": {},
   "source": [
    "#### <font color='#fc7202'>Task 4:</font>  \n",
    "1. Generate a **small sample** of size 15 from this distribution and plot its histogram.  \n",
    "2. Then, generate a **larger sample**. Choose the size yourself (for example, a few hundred or a few thousand observations), and plot a second histogram on the same scale.  \n",
    "\n",
    "> *Hint:* use `np.random.normal(mean, sd, size=n)` to generate the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6579126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb462fe5",
   "metadata": {},
   "source": [
    "#### <font color='#fc7202'>Task 5:</font>  \n",
    "Now, let’s use the same normal model to estimate a probability through simulation.  \n",
    "Assume that values **≤ 7.0** are considered unusually low for this measurement.  \n",
    "What is the probability that the next observation will fall into this range?\n",
    "\n",
    "1. Draw one sufficiently large synthetic sample from the same normal distribution.  \n",
    "2. Count how many of your simulated values are ≤ 7.0.  \n",
    "3. Compute the fraction of such observations (this represents your simulated probability).  \n",
    "4. Compare your simulated result with the analytical probability obtained using  \n",
    "\\begin{equation} P(X \\le 7.0) = \\texttt{norm.cdf(7.0, loc=mean, scale=sd)} \\end{equation}\n",
    "\n",
    "> *Hint:* You can use `np.mean(sample <= 7.0)` to calculate the fraction of simulated values ≤ 7.0.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "428fdbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb31baf2",
   "metadata": {},
   "source": [
    "#### <font color='#fc7202'>Task 6:</font>\n",
    "Assume the true process follows a normal distribution with mean = 10.0 and standard deviation of 1.8.\n",
    "\n",
    "You run an experiment with *n* = 600 observations and obtain a sample mean of 10.5.  \n",
    "How surprising is this result if the true mean is really 10.0?\n",
    "\n",
    "1. Simulate many experiments: in each repetition, draw `n = 600` values from `Normal(10.0, 1.8)`.  \n",
    "2. Compute the sample mean for each repetition.  \n",
    "3. Estimate the probability \n",
    "   \\begin{equation} P(\\bar{X} \\ge 10.5 \\mid \\mu=10.0, \\sigma=1.8, n=600) \\end{equation}\n",
    "   as the fraction of simulated means that are ≥ 10.5.  \n",
    "4. Visualize the sampling distribution of the simulated means (histogram) and add a vertical line at 10.5.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "de7202ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf127f4",
   "metadata": {},
   "source": [
    "In the previous task, we repeated the experiment many times and computed the sample mean each round.  \n",
    "The histogram of those sample means looked bell-shaped.  \n",
    "\n",
    "That is exactly the **Central Limit Theorem (CLT)** in action:\n",
    "- Regardless of the original data’s distribution (as long as observations are independent and identically distributed (i.i.d.) with finite variance),\n",
    "- the sampling distribution of the mean $\\bar X$ becomes approximately **Normal** as $n$ grows,\n",
    "- centered at the true mean $\\mu$ with standard deviation $\\sigma/\\sqrt{n}$.\n",
    "\n",
    "So, the bell shape you observed for the collection of sample means is *evidence of the CLT*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148b9659",
   "metadata": {},
   "source": [
    "#### <font color='#fc7202'>Task 7:</font>\n",
    "Let’s test whether the sample mean looks approximately normal even when the underlying data are not normal.\n",
    "We’ll use an exponential distribution.\n",
    "\n",
    "In `Python`, we can simulate such data using:\n",
    "```python\n",
    "np.random.exponential(scale=1/lam, size=n)\n",
    "```\n",
    "where:\n",
    "- `lam` is the rate parameter *λ*,\n",
    "- `1/lam` is the mean (the `scale` in `NumPy`’s function), and\n",
    "- `size` is the number of values you want to generate.\n",
    "\n",
    "1. Choose a sample size *n* (for example, 600) and a rate *λ* (for example, 0.1).\n",
    "2. Repeat the experiment many times (e.g., 20 000 repetitions): in each repetition, draw *n* values from `np.random.exponential(scale=1/lam, size=n)` and compute their sample mean.\n",
    "3. Plot a histogram of all simulated sample means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a0ae9b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
